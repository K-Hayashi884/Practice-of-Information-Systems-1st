{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"tocheading\">Table of Contents</h1>\n",
    "<div id=\"toc\"></div>\n",
    "<script src=\"https://kmahelona.github.io/ipython_notebook_goodies/ipython_notebook_toc.js\"></script>\n",
    "\n",
    "type1の店(tokubai.co.jpのリンクを踏むとチラシの画像が表示されるような店)\n",
    "\n",
    "type2の店(tokubai.co.jpのリンクを踏むと具体的な特売商品が文字列で表示されるような店)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全体の流れ\n",
    "- 1.リスト`links1`にチラシを取得する店の階層1リンクを格納(例:https://tokubai.co.jp/%E3%83%A9%E3%82%A4%E3%83%95/9470)\n",
    "- 2.店ごとに取得する条件が異なるため、`getlinks12(link1)`という関数を作成。この関数は`links1`に含まれる適切なチラシの階層2リンク(string)のlist(`links2raw`)を返す\n",
    "- 3.`links2raw`には最新ではないチラシも含まれるため、関数`get_new_urls(links2raw)`を作成。`./urls.txt`を利用。返り値`links2`には新しいチラシの階層2リンク\n",
    "- [4.`get_urls()`で階層2のリンクを階層3のリンク`links3`に変換](#4.`get_urls()`で階層2のリンクを階層3のリンクに変換 )\n",
    "\n",
    "- ([5.`DLjpg()`で内部にダウンロード](#5.`DLjpg()`で内部にダウンロード))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#関数設定した後に実行する部分\n",
    "links1 = [\"url_life_kitashirakawa\",\"url_coremo\",\"url_life_higasi1jou\",\"url...\"]\n",
    "links2raw = link1_to_link2(links1)\n",
    "links2 = get_new_urls=(links2raw)\n",
    "links3 = get_urls(links2)\n",
    "DLjpg(links3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 事前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import calendar\n",
    "#ユーザエージェント変更\n",
    "ua = \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"\n",
    "headers = {'User-Agent': ua}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.リスト`links1`にチラシを取得する店の階層1リンクを格納\n",
    "一旦ライフとグレースたなかだけで"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "links1 = []\n",
    "links1.append(\"https://tokubai.co.jp/%E3%83%A9%E3%82%A4%E3%83%95/9470\") #ライフ\n",
    "links1.append(\"https://tokubai.co.jp/%E3%82%B0%E3%83%AC%E3%83%BC%E3%82%B9%E3%81%9F%E3%81%AA%E3%81%8B/12265\") #グレースたなか"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.店ごとに取得する条件が異なるため、`link1_to_link2(link1)`という関数を作成。この関数は、リスト`links1`に含まれる適切なチラシの階層2リンク(string)のlist(`links2raw`)を返す\n",
    "\n",
    "ライフとグレースたなかだけなのは同様\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link1_to_link2(links1):\n",
    "    links2raw = [] #最終的には取得日に乗っているチラシのリンク(link2)一覧が格納される\n",
    "    for link1 in links1:\n",
    "        if \"%E3%83%A9%E3%82%A4%E3%83%95\" in link1: #ライフの場合\n",
    "            r = requests.get(link1,headers=headers)\n",
    "            soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "            elements = soup.find_all(class_=\"image_element\")\n",
    "            for element in elements:\n",
    "                link = element.get(\"href\")\n",
    "                l = \"https://tokubai.co.jp\"\n",
    "                date = element.find(class_=\"description\").string\n",
    "                if date.count(\"月\") == 1: #チラシ掲載期間が月を跨がない場合 例：/n2023年4月2〜4日まで/n -> 2023,4,2,4\n",
    "                    date = date[1:-1].replace(\"月\",\",\").replace(\"〜\",\",\").replace(\"日まで\",\",\").replace(\"年\",\",\")\n",
    "                    dates = date.split(\",\")\n",
    "                    period = int(dates[3]) - int(dates[2])\n",
    "                \n",
    "                else: #チラシ掲載期間が月を跨ぐ場合　例：/n2023年4月29日〜5月2日まで/n  -> 2023,4,29,5,2\n",
    "                    date = date[1:-1].replace(\"月\",\",\").replace(\"日〜\",\",\").replace(\"日まで\",\",\").replace(\"年\",\",\")\n",
    "                    dates = date.split(\",\")\n",
    "                    period = int(dates[4]) - int(dates[2]) + calendar.monthrange(2023, int(dates[1])+1)[1]\n",
    "                if period < 6: #ライフでは一般的に掲載期間が5日以下のものが取得したいチラシなので\n",
    "                    links2raw.append(l+link)\n",
    "\n",
    "        elif \"%E3%82%B0%E3%83%AC%E3%83%BC%E3%82%B9%E3%81%9F%E3%81%AA%E3%81%8B\" in link1: #グレースたなかの場合\n",
    "            r = requests.get(link1,headers=headers)\n",
    "            soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "            elements = soup.find_all(class_=\"image_element\")\n",
    "            for element in elements:\n",
    "                link = element.get(\"href\")\n",
    "                l = \"https://tokubai.co.jp\"\n",
    "                date = element.find(class_=\"description\").string\n",
    "                links2raw.append(l+link)\n",
    "\n",
    "    return links2raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://tokubai.co.jp/%E3%83%A9%E3%82%A4%E3%83%95/9470/leaflets/41521798',\n",
       " 'https://tokubai.co.jp/%E3%83%A9%E3%82%A4%E3%83%95/9470/leaflets/41521824',\n",
       " 'https://tokubai.co.jp/%E3%82%B0%E3%83%AC%E3%83%BC%E3%82%B9%E3%81%9F%E3%81%AA%E3%81%8B/12265/leaflets/41550454',\n",
       " 'https://tokubai.co.jp/%E3%82%B0%E3%83%AC%E3%83%BC%E3%82%B9%E3%81%9F%E3%81%AA%E3%81%8B/12265/leaflets/41550455']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link1_to_link2(links1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.`links2raw`には最新ではないチラシも含まれるため、関数`get_new_urls(links2raw)`を作成。`./urls.txt`を利用。返り値`links2`には新しいチラシの階層2リンク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_urls(links2raw):\n",
    "    new_urls_list = []\n",
    "\n",
    "    with open('urls.txt',\"r\") as f: #urls.txtの中には昨日使用したlink2リンクの一覧がある\n",
    "        lines = f.readlines()\n",
    "        lines = [line.replace(\"¥n\",\"\").replace(\"\\n\",\"\") for line in lines] #改行文字削除 怖かったので\\と¥を書いた\n",
    "\n",
    "    for link2raw in links2raw:\n",
    "        if link2raw in lines: #昨日使用したリンクは無視\n",
    "            #print(f\"link2raw {link2raw} is in links\")\n",
    "            continue\n",
    "        else: #昨日なかったリンクは欲しいのでnew_urls_listに格納\n",
    "            new_urls_list.append(link2raw)\n",
    "            \n",
    "    urls_new = map(lambda x: x + \"\\n\", links2raw)\n",
    "    #links2rawの内容をurls.txtに保存\n",
    "    with open('urls.txt', 'w', encoding='utf-8') as f:\n",
    "        f.writelines(urls_new)\n",
    "\n",
    "    return new_urls_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.`get_urls()`で階層2のリンクを階層3のリンクに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#まとめ： 関数内のurlにあるチラシ.jpgのリンクを出力する`get_url()`\n",
    "def get_url(urls):\n",
    "  new_urls = []\n",
    "  for url in urls:\n",
    "    r = requests.get(url,headers=headers)\n",
    "    soup = BeautifulSoup(r.text,\"html.parser\")\n",
    "    new_urls.append(soup.find('img',class_='leaflet').get('src')) \n",
    "  return new_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#関数設定した後に実行する部分\n",
    "#links1 = [\"url_life_kitashirakawa\",\"url_coremo\",\"url_life_higasi1jou\",\"url...\"]\n",
    "links2raw = link1_to_link2(links1)\n",
    "links2 = get_new_urls=(links2raw)\n",
    "links3 = get_url(links2)\n",
    "#DLjpg(links3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://image.tokubai.co.jp/images/bargain_office_leaflets/o=true/5887777.jpg?1682765571',\n",
       " 'https://image.tokubai.co.jp/images/bargain_office_leaflets/o=true/5887778.jpg?1682765611',\n",
       " 'https://image.tokubai.co.jp/images/bargain_leaflets/o=true/41717293.jpg?1683351879',\n",
       " 'https://image.tokubai.co.jp/images/bargain_leaflets/o=true/41717294.jpg?1683351901']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.`DLjpg()`で内部にダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DLjpg(links3):\n",
    "    for link in links3:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
